{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model as lm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS \n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A\n",
    "1.\tDownload the “dataset_lm.csv” file from Canvas and upload it to Jupyter Notebook. \n",
    "2.\tRun the OLS model by using the dependent and explanatory variables in the dataset. \n",
    "3.\tShow your summary table in Python and interpret your results in the summary report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_lm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>61.300432</td>\n",
       "      <td>0.338441</td>\n",
       "      <td>70.430598</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.525979</td>\n",
       "      <td>50.741115</td>\n",
       "      <td>-8.050843</td>\n",
       "      <td>39.075397</td>\n",
       "      <td>3</td>\n",
       "      <td>-29.197173</td>\n",
       "      <td>57.473862</td>\n",
       "      <td>15.505202</td>\n",
       "      <td>73.280605</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.602482</td>\n",
       "      <td>56.317474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>26.309237</td>\n",
       "      <td>-1.729712</td>\n",
       "      <td>47.087996</td>\n",
       "      <td>1</td>\n",
       "      <td>-19.034807</td>\n",
       "      <td>55.242929</td>\n",
       "      <td>28.001769</td>\n",
       "      <td>76.429649</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.941401</td>\n",
       "      <td>54.641620</td>\n",
       "      <td>14.295688</td>\n",
       "      <td>49.816798</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.910494</td>\n",
       "      <td>52.827988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>58.350627</td>\n",
       "      <td>18.322301</td>\n",
       "      <td>53.267835</td>\n",
       "      <td>0</td>\n",
       "      <td>-26.186201</td>\n",
       "      <td>36.702958</td>\n",
       "      <td>14.530116</td>\n",
       "      <td>51.275150</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.699670</td>\n",
       "      <td>46.443687</td>\n",
       "      <td>5.708762</td>\n",
       "      <td>52.751016</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.202345</td>\n",
       "      <td>52.467289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>31.954003</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>61.844132</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.881961</td>\n",
       "      <td>57.106851</td>\n",
       "      <td>21.786066</td>\n",
       "      <td>68.928442</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.166461</td>\n",
       "      <td>59.194840</td>\n",
       "      <td>8.365762</td>\n",
       "      <td>64.291056</td>\n",
       "      <td>1</td>\n",
       "      <td>-21.330017</td>\n",
       "      <td>50.237673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>50.590958</td>\n",
       "      <td>-3.107425</td>\n",
       "      <td>64.590632</td>\n",
       "      <td>1</td>\n",
       "      <td>-20.303215</td>\n",
       "      <td>56.374124</td>\n",
       "      <td>4.604237</td>\n",
       "      <td>49.501005</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.792745</td>\n",
       "      <td>45.594612</td>\n",
       "      <td>16.414449</td>\n",
       "      <td>66.957547</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.771155</td>\n",
       "      <td>43.603802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dependent Var  Explanatory Var #1  Explanatory Var #2   \n",
       "0        56.293458           13.698667           50.639873  \\\n",
       "1        58.473431            2.714725           65.845845   \n",
       "2        94.195330           11.618072           65.072497   \n",
       "3        29.074583            0.818623           45.408996   \n",
       "4        86.035569            9.077544           73.548021   \n",
       "..             ...                 ...                 ...   \n",
       "417      61.300432            0.338441           70.430598   \n",
       "418      26.309237           -1.729712           47.087996   \n",
       "419      58.350627           18.322301           53.267835   \n",
       "420      31.954003            0.436357           61.844132   \n",
       "421      50.590958           -3.107425           64.590632   \n",
       "\n",
       "     Explanatory Var #3  Explanatory Var #4  Explanatory Var #5   \n",
       "0                     0          -18.568035           45.121911  \\\n",
       "1                     1          -25.105932           47.190213   \n",
       "2                     0           -7.897464           52.163036   \n",
       "3                     1          -18.316132           54.356714   \n",
       "4                     0          -19.204165           47.186807   \n",
       "..                  ...                 ...                 ...   \n",
       "417                   0          -21.525979           50.741115   \n",
       "418                   1          -19.034807           55.242929   \n",
       "419                   0          -26.186201           36.702958   \n",
       "420                   0          -25.881961           57.106851   \n",
       "421                   1          -20.303215           56.374124   \n",
       "\n",
       "     Explanatory Var #6  Explanatory Var #7  Explanatory Var #8   \n",
       "0             11.412501           56.410757                   2  \\\n",
       "1             10.080280           65.383107                   3   \n",
       "2             11.057301           82.812717                   0   \n",
       "3              5.029029           48.812471                   1   \n",
       "4             12.128134           62.520911                   2   \n",
       "..                  ...                 ...                 ...   \n",
       "417           -8.050843           39.075397                   3   \n",
       "418           28.001769           76.429649                   0   \n",
       "419           14.530116           51.275150                   2   \n",
       "420           21.786066           68.928442                   0   \n",
       "421            4.604237           49.501005                   0   \n",
       "\n",
       "     Explanatory Var #9  Explanatory Var #10  Explanatory Var #11   \n",
       "0            -12.281132            38.996909            -3.010548  \\\n",
       "1            -36.763585            51.654939             4.991111   \n",
       "2            -15.733547            48.913837            -2.457696   \n",
       "3            -12.825591            45.851732            14.974177   \n",
       "4            -13.804860            47.765904             9.593982   \n",
       "..                  ...                  ...                  ...   \n",
       "417          -29.197173            57.473862            15.505202   \n",
       "418          -21.941401            54.641620            14.295688   \n",
       "419          -20.699670            46.443687             5.708762   \n",
       "420          -23.166461            59.194840             8.365762   \n",
       "421          -18.792745            45.594612            16.414449   \n",
       "\n",
       "     Explanatory Var #12  Explanatory Var #13  Explanatory Var #14   \n",
       "0              49.195073                    0           -21.153143  \\\n",
       "1              45.591729                    0            -6.474403   \n",
       "2              56.608806                    0           -27.903299   \n",
       "3              47.362594                    1           -10.064411   \n",
       "4              53.700562                    0           -17.546302   \n",
       "..                   ...                  ...                  ...   \n",
       "417            73.280605                    1            -3.602482   \n",
       "418            49.816798                    1           -13.910494   \n",
       "419            52.751016                    1            -6.202345   \n",
       "420            64.291056                    1           -21.330017   \n",
       "421            66.957547                    0           -15.771155   \n",
       "\n",
       "     Explanatory Var #15  \n",
       "0              46.919314  \n",
       "1              53.383508  \n",
       "2              48.515026  \n",
       "3              55.266254  \n",
       "4              48.150543  \n",
       "..                   ...  \n",
       "417            56.317474  \n",
       "418            52.827988  \n",
       "419            52.467289  \n",
       "420            50.237673  \n",
       "421            43.603802  \n",
       "\n",
       "[422 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 7.325e+30\n",
      "Date:                Mon, 23 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        15:55:14   Log-Likelihood:                 12332.\n",
      "No. Observations:                 422   AIC:                        -2.463e+04\n",
      "Df Residuals:                     406   BIC:                        -2.457e+04\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  32.0000    4.4e-14   7.27e+14      0.000      32.000      32.000\n",
      "Explanatory Var #1      1.3000   3.55e-16   3.66e+15      0.000       1.300       1.300\n",
      "Explanatory Var #2      1.7000   2.58e-16   6.58e+15      0.000       1.700       1.700\n",
      "Explanatory Var #3      6.2000   4.96e-15   1.25e+15      0.000       6.200       6.200\n",
      "Explanatory Var #4      2.1000   3.05e-16   6.88e+15      0.000       2.100       2.100\n",
      "Explanatory Var #5     -0.9000   3.58e-16  -2.52e+15      0.000      -0.900      -0.900\n",
      "Explanatory Var #6   7.177e-16   2.16e-16      3.325      0.001    2.93e-16    1.14e-15\n",
      "Explanatory Var #7  -3.743e-16   1.67e-16     -2.244      0.025   -7.02e-16   -4.64e-17\n",
      "Explanatory Var #8  -9.631e-15   2.27e-15     -4.249      0.000   -1.41e-14   -5.18e-15\n",
      "Explanatory Var #9  -9.871e-16    2.9e-16     -3.406      0.001   -1.56e-15   -4.17e-16\n",
      "Explanatory Var #10 -7.971e-16   3.61e-16     -2.207      0.028   -1.51e-15   -8.71e-17\n",
      "Explanatory Var #11 -2.137e-15   3.49e-16     -6.119      0.000   -2.82e-15   -1.45e-15\n",
      "Explanatory Var #12 -8.639e-16   2.61e-16     -3.306      0.001   -1.38e-15    -3.5e-16\n",
      "Explanatory Var #13  1.221e-15   5.01e-15      0.244      0.807   -8.62e-15    1.11e-14\n",
      "Explanatory Var #14 -1.465e-15   3.07e-16     -4.766      0.000   -2.07e-15   -8.61e-16\n",
      "Explanatory Var #15 -6.696e-16   3.66e-16     -1.829      0.068   -1.39e-15    4.99e-17\n",
      "==============================================================================\n",
      "Omnibus:                        1.429   Durbin-Watson:                   1.847\n",
      "Prob(Omnibus):                  0.490   Jarque-Bera (JB):                1.341\n",
      "Skew:                           0.009   Prob(JB):                        0.511\n",
      "Kurtosis:                       2.724   Cond. No.                     2.55e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = df[\"Dependent Var\"]\n",
    "X = df.drop(\"Dependent Var\", axis=1)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B\n",
    "1.\tUse error values from the OLS model to calculate their standard deviation and autocorrelation values for the first three lags. \n",
    "2.\tThen, run the GLS model accordingly. \n",
    "3.\tShow your summary table in Python and interpret your results in the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of OLS Residuals: 4.933401227123459e-14\n",
      "Autocorrelation for the first three lags:\n",
      "Lag 1: 0.06780015960053946\n",
      "Lag 2: 0.017936447749035474\n",
      "Lag 3: 0.05468134594634336\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals\n",
    "ols_residuals = ols_model.resid\n",
    "\n",
    "# Calculate standard deviation of residuals\n",
    "ols_residuals_std = ols_residuals.std()\n",
    "\n",
    "autocorrelation_lag1 = np.corrcoef(ols_residuals[:-1], ols_residuals[1:])[0, 1]\n",
    "autocorrelation_lag2 = np.corrcoef(ols_residuals[:-2], ols_residuals[2:])[0, 1]\n",
    "autocorrelation_lag3 = np.corrcoef(ols_residuals[:-3], ols_residuals[3:])[0, 1]\n",
    "\n",
    "print(f\"Standard Deviation of OLS Residuals: {ols_residuals_std}\")\n",
    "print(\"Autocorrelation for the first three lags:\")\n",
    "print(f\"Lag 1: {autocorrelation_lag1}\")\n",
    "print(f\"Lag 2: {autocorrelation_lag2}\")\n",
    "print(f\"Lag 3: {autocorrelation_lag3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
      "Model:                            GLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.495e+30\n",
      "Date:                Mon, 23 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        15:55:14   Log-Likelihood:                 12229.\n",
      "No. Observations:                 422   AIC:                        -2.443e+04\n",
      "Df Residuals:                     406   BIC:                        -2.436e+04\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  32.0000   5.62e-14   5.69e+14      0.000      32.000      32.000\n",
      "Explanatory Var #1      1.3000   4.54e-16   2.86e+15      0.000       1.300       1.300\n",
      "Explanatory Var #2      1.7000    3.3e-16   5.16e+15      0.000       1.700       1.700\n",
      "Explanatory Var #3      6.2000   6.33e-15    9.8e+14      0.000       6.200       6.200\n",
      "Explanatory Var #4      2.1000    3.9e-16   5.39e+15      0.000       2.100       2.100\n",
      "Explanatory Var #5     -0.9000   4.57e-16  -1.97e+15      0.000      -0.900      -0.900\n",
      "Explanatory Var #6  -8.262e-16   2.76e-16     -2.997      0.003   -1.37e-15   -2.84e-16\n",
      "Explanatory Var #7   1.041e-17   2.13e-16      0.049      0.961   -4.08e-16    4.29e-16\n",
      "Explanatory Var #8  -9.326e-15   2.89e-15     -3.223      0.001    -1.5e-14   -3.64e-15\n",
      "Explanatory Var #9   1.084e-15    3.7e-16      2.931      0.004    3.57e-16    1.81e-15\n",
      "Explanatory Var #10 -5.289e-15   4.61e-16    -11.470      0.000    -6.2e-15   -4.38e-15\n",
      "Explanatory Var #11  2.439e-15   4.46e-16      5.470      0.000    1.56e-15    3.32e-15\n",
      "Explanatory Var #12  3.088e-16   3.34e-16      0.926      0.355   -3.47e-16    9.65e-16\n",
      "Explanatory Var #13 -3.886e-15   6.39e-15     -0.608      0.544   -1.65e-14    8.68e-15\n",
      "Explanatory Var #14  3.062e-16   3.92e-16      0.780      0.436   -4.65e-16    1.08e-15\n",
      "Explanatory Var #15 -2.706e-15   4.67e-16     -5.791      0.000   -3.62e-15   -1.79e-15\n",
      "==============================================================================\n",
      "Omnibus:                        4.302   Durbin-Watson:                   1.560\n",
      "Prob(Omnibus):                  0.116   Jarque-Bera (JB):                4.251\n",
      "Skew:                           0.211   Prob(JB):                        0.119\n",
      "Kurtosis:                       2.747   Cond. No.                     2.55e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:130: ValueWarning: unknown kwargs ['rho']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import GLS\n",
    "\n",
    "# GLS model with the specified autocorrelation structure\n",
    "gls_model = GLS(y, X, sigma=ols_residuals_std, rho=[autocorrelation_lag1, autocorrelation_lag2, autocorrelation_lag3])\n",
    "gls_results = gls_model.fit()\n",
    "\n",
    "print(gls_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C\n",
    "1.\tSplit the dataset into two as the training and test sets (test size = 0.5). \n",
    "2.\tRun the Lasso model with alpha=1 and estimate the coefficients using the training set. \n",
    "3.\tThen, calculate the mean absolute percentage error using the test set. \n",
    "4.\tFind an approximate value for alpha that minimizes the mean absolute percentage error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Coefficients:\n",
      "Explanatory Var #1: 0.0000\n",
      "Explanatory Var #2: 1.2697\n",
      "Explanatory Var #3: 1.6839\n",
      "Explanatory Var #4: 2.0263\n",
      "Explanatory Var #5: 2.0876\n",
      "Explanatory Var #6: -0.9175\n",
      "Explanatory Var #7: -0.0000\n",
      "Explanatory Var #8: 0.0000\n",
      "Explanatory Var #9: -0.0000\n",
      "Explanatory Var #10: 0.0000\n",
      "Explanatory Var #11: -0.0000\n",
      "Explanatory Var #12: 0.0131\n",
      "Explanatory Var #13: 0.0000\n",
      "Explanatory Var #14: -0.0000\n",
      "Explanatory Var #15: 0.0000\n",
      "Explanatory Var #16: -0.0362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "#Lasso model with alpha=1\n",
    "lasso_model = Lasso(alpha=1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "lasso_coefficients = lasso_model.coef_\n",
    "\n",
    "print(\"Lasso Coefficients:\")\n",
    "for i, coef in enumerate(lasso_coefficients):\n",
    "    print(f\"Explanatory Var #{i+1}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 4.43%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "\n",
    "absolute_percentage_errors = abs((y_test - lasso_predictions) / y_test) * 100\n",
    "mape = absolute_percentage_errors.mean()\n",
    "print(\"Mean Absolute Percentage Error (MAPE): {:.2f}%\".format(mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha which minimizes the MAPE: 0.0001\n",
      "MAPE with Optimal Alpha: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# random range of alpha values to search for\n",
    "alphas = np.logspace(-4, 4, 9) \n",
    "\n",
    "# Cross-validate\n",
    "lasso_cv_model = LassoCV(alphas=alphas, cv=5) \n",
    "lasso_cv_model.fit(X_train, y_train)\n",
    "\n",
    "optimal_alpha = lasso_cv_model.alpha_\n",
    "\n",
    "lasso_optimal_model = Lasso(alpha=optimal_alpha)\n",
    "lasso_optimal_model.fit(X_train, y_train)\n",
    "\n",
    "lasso_optimal_predictions = lasso_optimal_model.predict(X_test)\n",
    "mape_optimal = mean_absolute_error(y_test, lasso_optimal_predictions)\n",
    "\n",
    "print(\"Optimal Alpha which minimizes the MAPE:\", optimal_alpha)\n",
    "print(\"MAPE with Optimal Alpha: {:.2f}%\".format(mape_optimal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART D\n",
    "1.\tUse the demand data given in the table and develop an appropriate forecasting model (i.e., the tailored regularization discussed in the class—see your slides for more info) that exploits the available information given in the table as much as possible.\n",
    "2.\tInterpret your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Demand Source: Advanced Demand (L)\n",
      "R-squared Baseline OLS: 0.504550248064856\n",
      "R-squared (Tailored Regularization): 0.9123\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = [\n",
    "    [100, 71],\n",
    "    [112, 30],\n",
    "    [107, 75],\n",
    "    [103, 64],\n",
    "    [91, 41],\n",
    "    [85, 51],\n",
    "    [84, 42],\n",
    "    [85, 51],\n",
    "    [79, 57],\n",
    "    [81, 49],\n",
    "    [134, 134],\n",
    "    [86, 52],\n",
    "    [99, 99],\n",
    "    [89, 56],\n",
    "    [111, 81],\n",
    "    [114, 79],\n",
    "    [118, 73],\n",
    "    [163, 163],\n",
    "    [193, 193],\n",
    "    [143, 99],\n",
    "    [144, 91],\n",
    "    [202, 202],\n",
    "    [158, 105],\n",
    "    [160, 101],\n",
    "    [144, 96]\n",
    "]\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "Y = data[1:, 0]  # Demand\n",
    "X = data[:-1, 0]  # Demand (t-1)\n",
    "L = data[1:, 1]  # Advanced Demand\n",
    "\n",
    "# Ordinary Least Squares (OLS) model\n",
    "X_OLS = np.vstack((np.ones(len(X)), X)).T\n",
    "beta_ols = np.linalg.lstsq(X_OLS, Y, rcond=None)[0]\n",
    "\n",
    "# Optimization Problem\n",
    "def objective_function(beta, Y, X, L):\n",
    "    forecasted_demand = X.dot(beta)\n",
    "    return np.linalg.norm(Y - forecasted_demand)\n",
    "\n",
    "def constraint_function(beta, X, L):\n",
    "    return X.dot(beta) - L\n",
    "\n",
    "# constraints of the objective function\n",
    "constraints = {'type': 'ineq', 'fun': constraint_function, 'args': (X, L)}\n",
    "\n",
    "initial_guess = np.zeros(X.shape[0])\n",
    "\n",
    "# using minimize function to solve objective function\n",
    "result = minimize(objective_function, initial_guess, args=(Y, X, L), constraints=constraints)\n",
    "\n",
    "# Calculate R-squared for Baseline OLS\n",
    "X_OLS = sm.add_constant(X)\n",
    "model_ols = sm.OLS(Y, X_OLS)\n",
    "result_ols = model_ols.fit()\n",
    "forecasted_demand_ols = result_ols.predict(X_OLS)\n",
    "r2_baseline = r2_score(Y, forecasted_demand_ols)\n",
    "\n",
    "# decide which demand to use based on lambda values. Use forecasted demand when lambda is negative. Use Advanced Demand (L) when lambda is positive\n",
    "lambda_value = result.fun\n",
    "if lambda_value < 0:\n",
    "    forecast_source = forecasted_demand_ols\n",
    "else:\n",
    "    forecast_source = L \n",
    "\n",
    "# Calculate the forecasted demand and R-squared for Tailored Regularization\n",
    "X_prime = np.column_stack((X, forecast_source))\n",
    "X_prime = sm.add_constant(X_prime)\n",
    "model_tailored = sm.OLS(Y, X_prime)\n",
    "result_tailored = model_tailored.fit()\n",
    "forecasted_demand = result_tailored.predict(X_prime)\n",
    "\n",
    "SSE = np.sum((Y - forecasted_demand) ** 2)\n",
    "SST = np.sum((Y - np.mean(Y)) ** 2)\n",
    "r_squared = 1 - (SSE / SST)\n",
    "\n",
    "if lambda_value < 0:\n",
    "    print(\"Chosen Demand Source: Forecasted Demand\")\n",
    "else:\n",
    "    print(\"Chosen Demand Source: Advanced Demand (L)\")\n",
    "\n",
    "print(f\"R-squared Baseline OLS: {r2_baseline}\")\n",
    "print(f\"R-squared (Tailored Regularization): {r_squared:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
